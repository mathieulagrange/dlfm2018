features === {'mel', 'mfcc','scat', 'null'} % type of features used (null is used for checking file access)
sct === [25, 128, 250, 500, 1000] % window size in ms
projection =2:== {'none', 'lmnn', 'lda'} % type of projection
split =2:== {'none', '50', '25', '10', 'octave'} % databse split, nukbers are random samples, octave concider only the octave 4
test =2:=4/[2 3 4]= [0, 1] % in test mode, the data is different for step 2 (projection) and step 3 (test), the larger split goes to step 2
reference =2:== {'family', 'instrument', 'mode', 'modeFamily', 'judgments'} % reference to compute the metric: 'family' instruments grouped if the body is modified (for example by using a sordina), 'instruments' musical instruments separated if the body is modified, 'modes' separated if instrument and playing technique is different, 'modeFamily' playing techniques merged if instruments are differents, 'judgments' set of clustering given by perceptual test 
randomize =2:== [0, 1] % randomize features to check effect of dimensionality in learning
expand =2:=1/2= [0, 494, 756, 876, 1032] % expand features using monomials to check effect of dimensionality in learning
cut =2:=1/2= [0, 1] % keep only the 13 first coeffs for mfccs
median =2:=1/3= [0, 1] % use median renormalization for scattering features
compress =2:=1/3= [0, 1] % use log compression for scattering features
standardize =2:== [0, 1] % standardize features at the end
neighbors =2:== 5 % number of neighbors used for  lmnn learning and performance computation
averageJudgment =2:=6/5= [0, 1] % use cluster ensemble techniques http://strehl.com/soft.html to obtain one clustering
separateJudgment =3=3/2= [0, 1] % evaluate each projection and average performance